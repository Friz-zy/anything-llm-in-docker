version: '3.8'
services:
  anythingllm:
    image: mintplexlabs/anythingllm
    container_name: anythingllm
    user: "root" # fix for storage
    ports:
    - "3001:3001"
    cap_add:
      - SYS_ADMIN 
    # environment:
    # # Adjust for your environment
    #   - STORAGE_DIR=/app/server/storage
    #   - JWT_SECRET="make this a large list of random numbers and letters 20+"
    #   - LLM_PROVIDER=ollama
    #   - OLLAMA_BASE_PATH=http://127.0.0.1:11434
    #   - OLLAMA_MODEL_PREF=llama2
    #   - OLLAMA_MODEL_TOKEN_LIMIT=4096
    #   - EMBEDDING_ENGINE=ollama
    #   - EMBEDDING_BASE_PATH=http://127.0.0.1:11434
    #   - EMBEDDING_MODEL_PREF=nomic-embed-text:latest
    #   - EMBEDDING_MODEL_MAX_CHUNK_LENGTH=8192
    #   - VECTOR_DB=lancedb
    #   - WHISPER_PROVIDER=local
    #   - TTS_PROVIDER=native
    #   - PASSWORDMINCHAR=8
    env_file:
      - .env
    volumes:
      - ./data/anythingllm:/app/server/storage
    restart: always

  ollama:
    image: ollama/ollama
    container_name: ollama
    environment:
      OLLAMA_ORIGINS: '*'
      OLLAMA_HOST: '0.0.0.0'
    volumes:
      - './data/ollama:/root/.ollama'
    # privileged: true # for GPU
    restart: always
